{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ba4a65-c2de-48c0-b1ce-13bede4549b4",
   "metadata": {},
   "source": [
    "# Importing all required packages and exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d7220d-ded8-47fb-b6f9-7bcb10c5a52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\c4741\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df = pd.read_csv('/Users/c4741/Downloads/complaints.csv', skipfooter=1496058, engine='python')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13392620-0c81-4c59-8815-773f4372e06c",
   "metadata": {},
   "source": [
    "### The analysed column: Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b52247d-6472-4bd6-bb1e-891d7f38a8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       Attempts to collect debt not owed\n",
      "1                    Incorrect information on your report\n",
      "2                    Incorrect information on your report\n",
      "3                                   Communication tactics\n",
      "4       Problem with a credit reporting company's inve...\n",
      "                              ...                        \n",
      "1996    Problem with a credit reporting company's inve...\n",
      "1997                          Improper use of your report\n",
      "1998                          Improper use of your report\n",
      "1999    Problem with a credit reporting company's inve...\n",
      "2000                 Incorrect information on your report\n",
      "Name: Issue, Length: 2001, dtype: object\n"
     ]
    }
   ],
   "source": [
    "complaints = df['Issue']\n",
    "print(complaints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd2b301-6690-444f-b6fb-a29b3673aad2",
   "metadata": {},
   "source": [
    "## Categories of Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a56561-3fd9-46de-8ec4-2d0f0a25364f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Incorrect information on your report                                                729\n",
       "Problem with a credit reporting company's investigation into an existing problem    249\n",
       "Attempts to collect debt not owed                                                   178\n",
       "Improper use of your report                                                         101\n",
       "Managing an account                                                                  89\n",
       "                                                                                   ... \n",
       "Problem with customer service                                                         1\n",
       "Identity theft protection or other monitoring services                                1\n",
       "Identity theft / Fraud / Embezzlement                                                 1\n",
       "Confusing or missing disclosures                                                      1\n",
       "Loan modification,collection,foreclosure                                              1\n",
       "Name: Issue, Length: 63, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Issue'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff0ff0a-be5e-45a4-81ae-0282257646fa",
   "metadata": {},
   "source": [
    "## Clean the complaints text / Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c20cc7e-fb56-441a-9897-49fa5da1166f",
   "metadata": {},
   "source": [
    "##### Step 1. All cases have been converted to low\n",
    "##### Step 2. Each word from each row has been tokenized\n",
    "##### Step 3. The English stop words have been removed\n",
    "##### Step 4. The words have been stemmed\n",
    "##### Step 5. The words have been lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23206402-136c-465e-aea8-4c57c966bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Issue'] = df['Issue'].str.lower()\n",
    "\n",
    "df['Issue'] = df['Issue'].apply(word_tokenize)\n",
    "\n",
    "def stops_removal(text):\n",
    "    t = [token for token in text if token not in stopwords.words(\"english\")]\n",
    "    text = ' '.join(t)\n",
    "    return text\n",
    "\n",
    "df['Issue'] = df['Issue'].apply(stops_removal)\n",
    "\n",
    "df['Issue'] = df['Issue'].apply(word_tokenize)\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "df['Issue'] = df['Issue'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "df['Issue'] = df['Issue'].apply(lambda lz:[lmtzr.lemmatize(z) for z in lz])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cef2161-ea3d-4196-bcb0-ae4ae1a8c629",
   "metadata": {},
   "source": [
    "### The complaints are formatted with the purpose of creating the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec59527-f883-4e7b-a0c1-7cbf5e1b55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = []\n",
    "for row in df['Issue']:\n",
    "    complaints.append(row)\n",
    "\n",
    "res = [' '.join(ele) for ele in df['Issue']] #will be used later at BoW with Sklearn\n",
    "complaints = ' '.join(res)\n",
    "complaints = word_tokenize(complaints)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee362915-24eb-490a-97ea-ee202febe43c",
   "metadata": {},
   "source": [
    "### The vocabulary (wordset) has been created [each clean word from complaints appears just one time in vocabulary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a44a79f-654b-4bec-895e-c86302f6a7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attempt', 'collect', 'debt', 'owe', 'incorrect', 'inform', 'report', 'communic', 'tactic', 'problem', 'credit', 'compani', \"'s\", 'investig', 'exist', 'close', 'account', 'fraud', 'scam', 'appli', 'mortgag', 'refinanc', 'written', 'notif', 'end', 'loan', 'lea', 'alert', 'secur', 'freez', 'improp', 'use', 'troubl', 'payment', 'process', 'fals', 'statement', 'represent', 'took', 'threaten', 'take', 'negat', 'legal', 'action', 'deal', 'lender', 'servic', 'purchas', 'shown', 'manag', 'unabl', 'get', 'score', 'struggl', 'pay', 'featur', ',', 'term', 'transact', 'charg', 'fee', 'interest', \"n't\", 'expect', 'unexpect', 'repay', 'disclosur', 'verif', 'transfer', 'taking/threaten', 'illeg', 'advertis', 'market', 'includ', 'promot', 'offer', 'vehicl', 'damag', 'destroy', 'monitor', 'ident', 'theft', 'protect', 'open', 'caus', 'fund', 'low', 'make', 'issu', 'contact', 'someon', 'share', 'card', 'cont', \"'d\", 'line', 'limit', 'chang', 'mobil', 'wallet', 'shop', 'receiv', 'unauthor', 'custom', 'payoff', '/', 'embezzl', 'confus', 'miss', 'modif', 'foreclosur']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = []\n",
    "\n",
    "for w in complaints:\n",
    "    if w not in vocabulary:\n",
    "        vocabulary.append(w)\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97164ae5-8961-4cbf-a566-c80c05a0fc17",
   "metadata": {},
   "source": [
    "### Creating the dictionary for Bag of words which counts how often a word appears in a complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c821d495-4d4a-4fa4-b3cd-8d2a5dc254f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateBOW(vocabulary,complaint):\n",
    "    tf_diz = dict.fromkeys(vocabulary,0)\n",
    "    for word in complaint:\n",
    "        tf_diz[word]=complaint.count(word)\n",
    "    return tf_diz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c22017-3745-4aba-b537-32da3650b8fa",
   "metadata": {},
   "source": [
    "# Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1802945-eeee-464d-a150-8639f5fca6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   attempt  collect  debt  owe  incorrect  inform  report  communic  tactic  \\\n",
      "0        1        1     1    1          0       0       0         0       0   \n",
      "1        0        0     0    0          1       1       1         0       0   \n",
      "2        0        0     0    0          1       1       1         0       0   \n",
      "3        0        0     0    0          0       0       0         1       1   \n",
      "4        0        0     0    0          0       0       1         0       0   \n",
      "\n",
      "   problem  ...  receiv  unauthor  custom  payoff  /  embezzl  confus  miss  \\\n",
      "0        0  ...       0         0       0       0  0        0       0     0   \n",
      "1        0  ...       0         0       0       0  0        0       0     0   \n",
      "2        0  ...       0         0       0       0  0        0       0     0   \n",
      "3        0  ...       0         0       0       0  0        0       0     0   \n",
      "4        2  ...       0         0       0       0  0        0       0     0   \n",
      "\n",
      "   modif  foreclosur  \n",
      "0      0           0  \n",
      "1      0           0  \n",
      "2      0           0  \n",
      "3      0           0  \n",
      "4      0           0  \n",
      "\n",
      "[5 rows x 111 columns]\n"
     ]
    }
   ],
   "source": [
    "bows = []\n",
    "for r in df['Issue']:\n",
    "    b = calculateBOW(vocabulary, r)\n",
    "    bows.append(b)\n",
    "df_bow = pd.DataFrame(bows)\n",
    "print (df_bow.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce99a3b-cb74-4437-a82d-d27049203f19",
   "metadata": {},
   "source": [
    "### Creating the Bag of Words using sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "398b3e1f-d554-460d-a121-84e54c303203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   account  action  advertis  alert  appli  attempt  card  caus  chang  charg  \\\n",
      "0        0       0         0      0      0        1     0     0      0      0   \n",
      "1        0       0         0      0      0        0     0     0      0      0   \n",
      "2        0       0         0      0      0        0     0     0      0      0   \n",
      "3        0       0         0      0      0        0     0     0      0      0   \n",
      "4        0       0         0      0      0        0     0     0      0      0   \n",
      "\n",
      "   ...  transfer  troubl  unabl  unauthor  unexpect  use  vehicl  verif  \\\n",
      "0  ...         0       0      0         0         0    0       0      0   \n",
      "1  ...         0       0      0         0         0    0       0      0   \n",
      "2  ...         0       0      0         0         0    0       0      0   \n",
      "3  ...         0       0      0         0         0    0       0      0   \n",
      "4  ...         0       0      0         0         0    0       0      0   \n",
      "\n",
      "   wallet  written  \n",
      "0       0        0  \n",
      "1       0        0  \n",
      "2       0        0  \n",
      "3       0        0  \n",
      "4       0        0  \n",
      "\n",
      "[5 rows x 106 columns]\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "data = vect.fit_transform(res)\n",
    "data = pd.DataFrame(data.toarray(), columns=vect.get_feature_names_out())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39556aba-97d4-46dd-b3b9-531afb863f67",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5edebec4-eda2-49a3-bdff-170a43e9f377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   account  action  advertis  alert  appli   attempt  card  caus  chang  \\\n",
      "0      0.0     0.0       0.0    0.0    0.0  0.512721   0.0   0.0    0.0   \n",
      "1      0.0     0.0       0.0    0.0    0.0  0.000000   0.0   0.0    0.0   \n",
      "2      0.0     0.0       0.0    0.0    0.0  0.000000   0.0   0.0    0.0   \n",
      "3      0.0     0.0       0.0    0.0    0.0  0.000000   0.0   0.0    0.0   \n",
      "4      0.0     0.0       0.0    0.0    0.0  0.000000   0.0   0.0    0.0   \n",
      "\n",
      "   charg  ...  transfer  troubl  unabl  unauthor  unexpect  use  vehicl  \\\n",
      "0    0.0  ...       0.0     0.0    0.0       0.0       0.0  0.0     0.0   \n",
      "1    0.0  ...       0.0     0.0    0.0       0.0       0.0  0.0     0.0   \n",
      "2    0.0  ...       0.0     0.0    0.0       0.0       0.0  0.0     0.0   \n",
      "3    0.0  ...       0.0     0.0    0.0       0.0       0.0  0.0     0.0   \n",
      "4    0.0  ...       0.0     0.0    0.0       0.0       0.0  0.0     0.0   \n",
      "\n",
      "   verif  wallet  written  \n",
      "0    0.0     0.0      0.0  \n",
      "1    0.0     0.0      0.0  \n",
      "2    0.0     0.0      0.0  \n",
      "3    0.0     0.0      0.0  \n",
      "4    0.0     0.0      0.0  \n",
      "\n",
      "[5 rows x 106 columns]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "model = vectorizer.fit_transform(res)\n",
    "data_TF_IDF=pd.DataFrame(model.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "print(data_TF_IDF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec1328-516a-4fe5-9b2f-0203e91b9da2",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4bd9c55-d785-4548-8c97-6e47d73e6f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics: \n",
      "Topic  0 :  6.671158166130228 %\n",
      "Topic  1 :  6.67114775256597 %\n",
      "Topic  2 :  6.671149884339562 %\n",
      "Topic  3 :  73.30195980027976 %\n",
      "Topic  4 :  6.68458439668447 %\n"
     ]
    }
   ],
   "source": [
    "lda_model=LatentDirichletAllocation(n_components=5,learning_method='online',random_state=42,)\n",
    "lda_top=lda_model.fit_transform(model)\n",
    "\n",
    "print(\"Topics: \")\n",
    "for i,topic in enumerate(lda_top[0]):\n",
    "    print(\"Topic \",i,\": \",topic*100,\"%\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55466495-5431-4450-b9e7-154767e90974",
   "metadata": {},
   "source": [
    "## The most important words for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "326f7a46-6969-4c0c-9bfb-d467566f9676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "payment troubl process mortgag pay struggl communic tactic make appli \n",
      "\n",
      "Topic 1: \n",
      "incorrect inform report fals represent secur freez alert fraud statement \n",
      "\n",
      "Topic 2: \n",
      "problem credit compani investig exist report close account get lender \n",
      "\n",
      "Topic 3: \n",
      "collect owe attempt debt purchas shown statement problem scam fraud \n",
      "\n",
      "Topic 4: \n",
      "use improp manag account written notif debt report loan threaten \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = vect.get_feature_names_out()\n",
    "\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258afb7e-c2a0-4305-bb3a-4474c6ed3319",
   "metadata": {},
   "source": [
    "# LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeac54bb-24b0-47eb-bd81-1050e39c23a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics :\n",
      "Topic  0  :  5.831511928406042e-07\n",
      "Topic  1  :  0.00026915060232286954\n",
      "Topic  2  :  99.1368983581916\n",
      "Topic  3  :  -0.0010461751501298026\n",
      "Topic  4  :  -0.0002617803009388298\n"
     ]
    }
   ],
   "source": [
    "LSA_model = TruncatedSVD(n_components=5, algorithm='randomized', n_iter=10)\n",
    "lsa = LSA_model.fit_transform(model)\n",
    "l=lsa[0]\n",
    "\n",
    "print(\"Topics :\")\n",
    "for i,topic in enumerate(l):\n",
    "    print(\"Topic \",i,\" : \",topic*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80334425-5c4c-42ce-9ae2-9f498c63d86c",
   "metadata": {},
   "source": [
    "## The most important words for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0009241-d106-460e-9289-d1a084e6d62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "incorrect inform report problem credit investig compani exist improp use \n",
      "\n",
      "Topic 1: \n",
      "problem investig compani exist credit report purchas shown statement get \n",
      "\n",
      "Topic 2: \n",
      "debt attempt owe collect notif written cont verif disclosur foreclosur \n",
      "\n",
      "Topic 3: \n",
      "account manag close open incorrect inform loan charg lender lea \n",
      "\n",
      "Topic 4: \n",
      "use improp account report manag close troubl card open loan \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = vect.get_feature_names_out()\n",
    "\n",
    "for i, comp in enumerate(LSA_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
